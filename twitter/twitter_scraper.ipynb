{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e03481cc",
   "metadata": {},
   "source": [
    "# Importing the required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb68fcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from explicit import waiter, XPATH\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f7e687",
   "metadata": {},
   "source": [
    "# PART-1 OF THE CODE WHICH JUST SCRAPES THE USERNAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e87116",
   "metadata": {},
   "source": [
    "## Twitter Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9d3061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"@EdgeForex16\"\n",
    "password = \"Success01!\"\n",
    "account_to_be_scraped = \"ForexLiveInfo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef59d39d",
   "metadata": {},
   "source": [
    "# Script to scrape followers usernames and store in excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dcab287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|████████████████████████████████████████████████████████| 6.68M/6.68M [00:01<00:00, 3.57MB/s]\n"
     ]
    }
   ],
   "source": [
    "# CREATING LISTS TO STORE THE SCRAPED USERNAMES\n",
    "global usernames_ls\n",
    "usernames_ls = []\n",
    "\n",
    "# LOGIN FUNCTION IS USED TO LOGIN INTO THE GIVEN TWITTER ACOOUNT\n",
    "def login(driver):\n",
    "    driver.get(\"https://twitter.com/i/flow/login\")\n",
    "    waiter.find_write(driver, \"//*[@id='layers']/div/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div/div/div/div[5]/label/div/div[2]/div/input\", username, by=XPATH)\n",
    "    waiter.find_element(driver, \"//*[@id='layers']/div/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div/div/div/div[6]/div\", by=XPATH).click()\n",
    "    waiter.find_write(driver, \"//*[@id='layers']/div/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div[1]/div/div/div[3]/div/label/div/div[2]/div[1]/input\", password, by=XPATH)\n",
    "    waiter.find_element(driver, \"//*[@id='layers']/div/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div[2]/div/div[1]/div/div/div/div\", by=XPATH).click()\n",
    "    time.sleep(4)\n",
    "\n",
    "    \n",
    "# EXTARCT FOLLOWERS FUNCTION IS USED TO SCRAPE THE FOLLOWERS OF THE GIVEN TWITTER HANDLE AND STORE THEM IN A EXCEL FILE\n",
    "\n",
    "\n",
    "# extract followers takes two arguments driver: the selenium driver \n",
    "# and account_name: the twitter handle that is to be scraped\n",
    "\n",
    "def extract_followers_func(driver,account_name):\n",
    "    driver.get(f\"https://twitter.com/{account_name}/followers\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # getting the scraped page source\n",
    "    html_source = driver.page_source\n",
    "    sourcedata = html_source.encode('utf-8')\n",
    "    \n",
    "    # parsing the returned source with beautifulsoup\n",
    "    soup = BeautifulSoup( sourcedata , 'html.parser')\n",
    "    \n",
    "    # finding all the anchor tags with specified class since these anchor tags contains the usernames\n",
    "    users = soup.find_all('a',{'class':'css-4rbku5 css-18t94o4 css-1dbjc4n r-1loqt21 r-1wbh5a2 r-dnmrzs r-1ny4l3l'})\n",
    "    \n",
    "    # Iterating through latest scraped users and appending them into the list\n",
    "    for i in users:\n",
    "        usernames_ls.append((i['href'])[1:])\n",
    "        \n",
    "    # Calculating the last height till the web page is scrolled\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    # Scroling through next part of the web page\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(4)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "        time.sleep(3)\n",
    "        \n",
    "        # Repeating the above process of scraping the usernames\n",
    "        html_source = driver.page_source\n",
    "        sourcedata = html_source.encode('utf-8')\n",
    "        soup = BeautifulSoup( sourcedata , 'html.parser')\n",
    "        users = soup.find_all('a',{'class':'css-4rbku5 css-18t94o4 css-1dbjc4n r-1loqt21 r-1wbh5a2 r-dnmrzs r-1ny4l3l'})\n",
    "        for i in users:\n",
    "            usernames_ls.append((i['href'])[1:])\n",
    "    \n",
    "    # closing the driver \n",
    "    driver.quit()\n",
    "    \n",
    "    # removing the duplicated if any present in the scrpaed usernames\n",
    "    usernames = list(set(usernames_ls))\n",
    "    base = \"https://twitter.com/\"\n",
    "    global hyperlinks\n",
    "    hyperlinks = [base+i for i in usernames]\n",
    "    \n",
    "    # returning the two lists \n",
    "    # usernames : a list containing all the usernames of the given handle\n",
    "    # hyperlinks : a list containing twitter account link to the respective twitter handle \n",
    "    return usernames,hyperlinks\n",
    "    \n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install())) \n",
    "\n",
    "# CALLING THE \"login\" FUNCITON TO LOG INTO THE TWITTER ACCOUNT \n",
    "login(driver)\n",
    "try:\n",
    "    # CALLING THE \"extract_followers_func\" TO START SCRAPING THE FOLLOWERS\n",
    "    usernames_ls,hyper_links = extract_followers_func(driver=driver,account_name=account_to_be_scraped)\n",
    "\n",
    "    # CREATING HEADER FOR THE EXCEL\n",
    "    data = {\n",
    "            'Followers Usernames' : usernames_ls,\n",
    "            'Followers Hyperlinks' : hyper_links\n",
    "        }\n",
    "\n",
    "    # Creating a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Saving the df into excel\n",
    "    df.to_excel(\"twiterusernames_scrapedD.xlsx\")\n",
    "except:\n",
    "    data = {\n",
    "            'Followers Usernames' : usernames_ls,\n",
    "            'Followers Hyperlinks' : hyper_links\n",
    "        }\n",
    "\n",
    "    # Creating a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Saving the df into excel\n",
    "    df.to_excel(\"twiterusernames_scrapedD.xlsx\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab9d90d",
   "metadata": {},
   "source": [
    "# PART-2 OF THE CODE WHICH SCRAPES THE COMPLETE USER INFO OF EVERY SINGLE FOLLOWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36f0ba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLE THAT CONTAINS THE NAME OF THE TWITETR HANDLE WHOSE FOLLOWERS IS BEING SCRAPED\n",
    "import subprocess\n",
    "\n",
    "scraped_handle_name = account_to_be_scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "108623a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10555\n"
     ]
    }
   ],
   "source": [
    "# SUBPROCESS IS A LIBRARY THAT ENABLES PYTHON TO EXECUTE CMD COMMANDS WITHIN THE NOTEBOOK\n",
    "\n",
    "# reading the usernames from scraped excel in part-1 of the code\n",
    "excel_data_df = pd.read_excel('twiterusernames_scrapedD.xlsx')\n",
    "\n",
    "# extarting usernames from dataframe and converting them into list \n",
    "follwers_ls = excel_data_df[\"Followers Usernames\"].tolist()\n",
    "\n",
    "# printing the no.of usernames just for the idea\n",
    "print(len(follwers_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36af350",
   "metadata": {},
   "source": [
    "### CREATING THE HEADER FOR THE EXCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e16634b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Follower of</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Screen Name</th>\n",
       "      <th>Following</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Bio</th>\n",
       "      <th>Location</th>\n",
       "      <th>URL</th>\n",
       "      <th>Verified</th>\n",
       "      <th>Private</th>\n",
       "      <th>Joined</th>\n",
       "      <th>UTC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Follower of, User ID, Name, Screen Name, Following, Followers, Likes, Tweets, Bio, Location, URL, Verified, Private, Joined, UTC]\n",
       "Index: []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = [\n",
    "               'Follower of',\n",
    "               'User ID',\n",
    "               'Name',\n",
    "               'Screen Name', \n",
    "               'Following',\n",
    "               'Followers',\n",
    "               'Likes',\n",
    "               'Tweets',\n",
    "               'Bio',\n",
    "               'Location',\n",
    "               'URL',\n",
    "               'Verified',\n",
    "               'Private', \n",
    "               'Joined',\n",
    "               'UTC'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f919d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"error_counter\" IS LIST WHICH IS USED TO STORE THOSE USERNAMES THAT ARE CAUSING ERROR WHEN TRIED TO SCRAPE\n",
    "error_counter = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83b5e58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-10-09 21:29:48.875701'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime \n",
    "\n",
    "timestamp = str(datetime.datetime.now())\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce88f7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "follwers_ls = [\n",
    "    \n",
    "    'ParaRjs',\n",
    "'ForexLiveInfo',\n",
    "'FXWinnerEA'\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7e114f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:09<00:00,  3.20s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# ITERATING THROUGH EVERY FOLLOWER IN THE LIST\n",
    "for name in tqdm(follwers_ls):\n",
    "        try:\n",
    "            boo = subprocess.check_output([\"twint\", \"-u\",name,\"--user-full\"],shell=True, stderr=subprocess.STDOUT)\n",
    "            boo = boo.decode()\n",
    "\n",
    "            ls = list(map(str,boo.split(\"|\")))\n",
    "\n",
    "            list2 = [i.strip() for i in ls if \":\" in i]; response_dict = dict()\n",
    "\n",
    "            response_dict.update({'User ID':ls[0]})\n",
    "            response_dict.update({'Name':ls[1]})\n",
    "            response_dict.update({'Screen Name':ls[2]})\n",
    "            list1 = [i.strip() for i in list2]\n",
    "            for i in list1:\n",
    "                tls = i.split(\":\")\n",
    "                response_dict.update({tls[0]:tls[1]})\n",
    "            if list2!='DATA NOT FOUND':\n",
    "                response_dict.update({'Url':list2[4][4:]})\n",
    "\n",
    "            # PUSHING THE DATA INTO A TEMPORARY DATAFRAME,\n",
    "            # WHICH IS LATER APPENDED INTO THE MAIN DATAFRAME\n",
    "            tdf = {\n",
    "                   'Follower of': scraped_handle_name,\n",
    "                   'User ID': response_dict['User ID'],\n",
    "                   'Name': response_dict['Name'],\n",
    "                   'Screen Name' :response_dict['Screen Name'], \n",
    "                   'Following' :response_dict['Following'],\n",
    "                   'Followers':response_dict['Followers'] ,\n",
    "                   'Likes':response_dict['Likes'],\n",
    "                   'Tweets':response_dict['Tweets']  ,\n",
    "                   'Bio':response_dict['Bio'],\n",
    "                   'Location':response_dict['Location'],\n",
    "                   'URL':response_dict['Url']  ,\n",
    "                   'Verified':response_dict['Verified'],\n",
    "                   'Private':response_dict['Private'], \n",
    "                   'Joined':response_dict['Joined'],\n",
    "                   'UTC': timestamp\n",
    "                }\n",
    "            tdf = pd.DataFrame(tdf,index=[0])\n",
    "\n",
    "            # APPENDING THE TEMPORARY DATAFRAME INTO THE MAIN DATAFRAME\n",
    "            df = pd.concat([df,tdf], ignore_index = True)\n",
    "\n",
    "        #CODE MOVES INTO THIS SECTION IF AN ERROR OCCURS\n",
    "        except:\n",
    "\n",
    "            # STORING THOSE USERNAMES WHICH ARE CAUSING ERROR\n",
    "            error_counter.append(name)\n",
    "\n",
    "            # SAVING ALL THE DATA THAT IS SCRAPED TILL NOW IN AN EXCEL \n",
    "            # SO THAT THERE IS NO LOSS OF DATA\n",
    "            df.to_excel(\"master_twitter_scraped.xlsx\")\n",
    "\n",
    "        finally:\n",
    "            # SAVING ALL THE DATA THAT IS SCRAPED TILL NOW IN AN EXCEL \n",
    "            # SO THAT THERE IS NO LOSS OF DATA\n",
    "            df.to_excel(\"master_twitter_scraped.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b03e269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(error_counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf602dc9",
   "metadata": {},
   "source": [
    "# Scraping with SNSCRAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "06c097fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_response = subprocess.check_output(['snscrape','--jsonl','--with-entity','--max-results','0','twitter-user','nuvoforex'],shell=True, stderr=subprocess.STDOUT).decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee8939ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "scraped_details = []\n",
    "scraped_details.append(json.loads(scraped_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3a7b6481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://telegram.me/+hTMSInfl-Tw2NzU0'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_details[0]['link']['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "df4ae836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Follower of</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Screen Name</th>\n",
       "      <th>Following</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Bio</th>\n",
       "      <th>Location</th>\n",
       "      <th>URL</th>\n",
       "      <th>Verified</th>\n",
       "      <th>Private</th>\n",
       "      <th>Joined</th>\n",
       "      <th>UTC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ForexLiveInfo</td>\n",
       "      <td>2788849409</td>\n",
       "      <td>Edge Forex</td>\n",
       "      <td>nuvoforex</td>\n",
       "      <td>4908</td>\n",
       "      <td>1216</td>\n",
       "      <td>244</td>\n",
       "      <td>3941</td>\n",
       "      <td>We are FOREX signal service provider,who will ...</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>https://telegram.me/+hTMSInfl-Tw2NzU0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2014-09-28T11:32:37+00:00</td>\n",
       "      <td>2022-10-08 12:45:50.987249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Follower of     User ID        Name Screen Name  Following  Followers  \\\n",
       "0  ForexLiveInfo  2788849409  Edge Forex   nuvoforex       4908       1216   \n",
       "\n",
       "   Likes  Tweets                                                Bio  \\\n",
       "0    244    3941  We are FOREX signal service provider,who will ...   \n",
       "\n",
       "          Location                                    URL  Verified  Private  \\\n",
       "0  Toronto, Canada  https://telegram.me/+hTMSInfl-Tw2NzU0     False    False   \n",
       "\n",
       "                      Joined                         UTC  \n",
       "0  2014-09-28T11:32:37+00:00  2022-10-08 12:45:50.987249  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    url = scraped_details[0]['link']['url'] \n",
    "except:\n",
    "    url = \"DATA NOT FOUND\"\n",
    "\n",
    "tdf = {\n",
    "           'Follower of': scraped_handle_name,\n",
    "           'User ID': scraped_details[0]['id'],\n",
    "           'Name': scraped_details[0]['displayname'],\n",
    "           'Screen Name' :scraped_details[0]['username'], \n",
    "           'Following' :scraped_details[0]['friendsCount'],\n",
    "           'Followers':scraped_details[0]['followersCount'] ,\n",
    "           'Likes':scraped_details[0]['favouritesCount'],\n",
    "           'Tweets':scraped_details[0]['statusesCount']  ,\n",
    "           'Bio':scraped_details[0]['renderedDescription'],\n",
    "           'Location':scraped_details[0]['location'],\n",
    "           'URL':url,\n",
    "           'Verified':scraped_details[0]['verified'],\n",
    "           'Private':scraped_details[0]['protected'], \n",
    "           'Joined':scraped_details[0]['created'],\n",
    "           'UTC': timestamp\n",
    "                }\n",
    "tdf = pd.DataFrame(tdf,index=[0])\n",
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e69ef52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# ITERATING THROUGH EVERY FOLLOWER IN THE LIST\n",
    "for name in tqdm(follwers_ls):\n",
    "        #try:\n",
    "            scraped_response = subprocess.check_output(['snscrape','--jsonl','--with-entity','--max-results','0','twitter-user',name],shell=True, stderr=subprocess.STDOUT).decode()\n",
    "            scraped_details = []\n",
    "            scraped_details.append(json.loads(scraped_response))\n",
    "            try:\n",
    "                url = scraped_details[0]['link']['url'] \n",
    "            except:\n",
    "                url = \"DATA NOT FOUND\"\n",
    "\n",
    "            # PUSHING THE DATA INTO A TEMPORARY DATAFRAME,\n",
    "            # WHICH IS LATER APPENDED INTO THE MAIN DATAFRAME\n",
    "            tdf = {\n",
    "                   'Follower of': scraped_handle_name,\n",
    "                   'User ID': scraped_details[0]['id'],\n",
    "                   'Name': scraped_details[0]['displayname'],\n",
    "                   'Screen Name' :scraped_details[0]['username'], \n",
    "                   'Following' :scraped_details[0]['friendsCount'],\n",
    "                   'Followers':scraped_details[0]['followersCount'] ,\n",
    "                   'Likes':scraped_details[0]['favouritesCount'],\n",
    "                   'Tweets':scraped_details[0]['statusesCount']  ,\n",
    "                   'Bio':scraped_details[0]['renderedDescription'],\n",
    "                   'Location':scraped_details[0]['location'],\n",
    "                   'URL': url,\n",
    "                   'Verified':scraped_details[0]['verified'],\n",
    "                   'Private':scraped_details[0]['protected'], \n",
    "                   'Joined':scraped_details[0]['created'],\n",
    "                   'UTC': timestamp\n",
    "                }\n",
    "            tdf = pd.DataFrame(tdf,index=[0])\n",
    "\n",
    "            # APPENDING THE TEMPORARY DATAFRAME INTO THE MAIN DATAFRAME\n",
    "            df = pd.concat([df,tdf], ignore_index = True)\n",
    "            df.to_excel(\"master_twitter_scraped.xlsx\")\n",
    "\n",
    "#         # CODE MOVES INTO THIS SECTION IF AN ERROR OCCURS\n",
    "#         except:\n",
    "\n",
    "#             # STORING THOSE USERNAMES WHICH ARE CAUSING ERROR\n",
    "#             error_counter.append(name)\n",
    "\n",
    "#             # SAVING ALL THE DATA THAT IS SCRAPED TILL NOW IN AN EXCEL \n",
    "#             # SO THAT THERE IS NO LOSS OF DATA\n",
    "#             df.to_excel(\"master_twitter_scraped.xlsx\")\n",
    "\n",
    "#         finally:\n",
    "#             # SAVING ALL THE DATA THAT IS SCRAPED TILL NOW IN AN EXCEL \n",
    "#             # SO THAT THERE IS NO LOSS OF DATA\n",
    "#             df.to_excel(\"master_twitter_scraped.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24a88f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4651ac3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4288bb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "104d8ad5",
   "metadata": {},
   "source": [
    "# Viewing the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68918a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba6e6af",
   "metadata": {},
   "source": [
    "# Checking if there are any usernames that are not scraped\n",
    "\n",
    "### if list is empty then all the users are scraped successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8c2313e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a656a81",
   "metadata": {},
   "source": [
    "# Loading Data into Oracle DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7aa99357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cx_Oracle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19ae212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_data_df = pd.read_excel('master_twitter_scraped.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90acbeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_data_df.drop(\"DATA NOT FOUND\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f5302f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Follower of</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Screen Name</th>\n",
       "      <th>Following</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Bio</th>\n",
       "      <th>Location</th>\n",
       "      <th>URL</th>\n",
       "      <th>Verified</th>\n",
       "      <th>Private</th>\n",
       "      <th>Joined</th>\n",
       "      <th>UTC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FXWinnerEA</td>\n",
       "      <td>781065</td>\n",
       "      <td>syafrizan'</td>\n",
       "      <td>@icaudumai</td>\n",
       "      <td>171</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>159</td>\n",
       "      <td>Negara yang sarat dengan berita hoax'</td>\n",
       "      <td>indonesia'</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2009-09-09 06:11:08 UTC</td>\n",
       "      <td>2022-10-05 17:43:39.452314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FXWinnerEA</td>\n",
       "      <td>4532559400689667</td>\n",
       "      <td>oluaye federation'</td>\n",
       "      <td>@Tijaniadewalew1</td>\n",
       "      <td>87</td>\n",
       "      <td>15</td>\n",
       "      <td>36</td>\n",
       "      <td>52</td>\n",
       "      <td>male'</td>\n",
       "      <td>Nigeria'</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-03-17 18:58:21 UTC</td>\n",
       "      <td>2022-10-05 17:43:39.452314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FXWinnerEA</td>\n",
       "      <td>16249377</td>\n",
       "      <td>feraazz'</td>\n",
       "      <td>@feraazz001</td>\n",
       "      <td>2244</td>\n",
       "      <td>818</td>\n",
       "      <td>37</td>\n",
       "      <td>42</td>\n",
       "      <td>Forex trader'</td>\n",
       "      <td>Vereinigtes K\\\\xf6nigreich'</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2014-12-11 21:10:55 UTC</td>\n",
       "      <td>2022-10-05 17:43:39.452314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FXWinnerEA</td>\n",
       "      <td>458493</td>\n",
       "      <td>Tokumendo'</td>\n",
       "      <td>@tokumendo</td>\n",
       "      <td>2271</td>\n",
       "      <td>238</td>\n",
       "      <td>3676</td>\n",
       "      <td>23454</td>\n",
       "      <td>'</td>\n",
       "      <td>S\\\\xe3o Paulo, Brasil'</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2009-06-30 17:30:54 UTC</td>\n",
       "      <td>2022-10-05 17:43:39.452314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FXWinnerEA</td>\n",
       "      <td>47273373018157060</td>\n",
       "      <td>ashkan koala'</td>\n",
       "      <td>@AshkanKoala</td>\n",
       "      <td>211</td>\n",
       "      <td>116</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>\\\\U0001f4bbMQLprogrammer and forex strategy bu...</td>\n",
       "      <td>'</td>\n",
       "      <td>https://t.co/qmIZ6jpYHp</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-01-07 20:07:07 UTC</td>\n",
       "      <td>2022-10-05 17:43:39.452314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>FXWinnerEA</td>\n",
       "      <td>32278163385987072</td>\n",
       "      <td>EasyForex'</td>\n",
       "      <td>@EasyForex4</td>\n",
       "      <td>3995</td>\n",
       "      <td>5464</td>\n",
       "      <td>389</td>\n",
       "      <td>757</td>\n",
       "      <td>#forex #forextrader #bitcoin #trading #forextr...</td>\n",
       "      <td>Sweden'</td>\n",
       "      <td>https://t.co/nCqaaJY48i</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-02-25 12:16:35 UTC</td>\n",
       "      <td>2022-10-05 17:43:39.452314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>FXWinnerEA</td>\n",
       "      <td>99271220345688064</td>\n",
       "      <td>Bigbucks'</td>\n",
       "      <td>@bigbucks2006</td>\n",
       "      <td>3211</td>\n",
       "      <td>963</td>\n",
       "      <td>81</td>\n",
       "      <td>3876</td>\n",
       "      <td>Stocks and shares'</td>\n",
       "      <td>'</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-08-28 09:03:00 UTC</td>\n",
       "      <td>2022-10-05 17:43:39.452314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>FXWinnerEA</td>\n",
       "      <td>17579047984156672</td>\n",
       "      <td>Merlin Emnx'</td>\n",
       "      <td>@MerlinEmnx</td>\n",
       "      <td>1342</td>\n",
       "      <td>275</td>\n",
       "      <td>198</td>\n",
       "      <td>12</td>\n",
       "      <td>Am slow walker but never well back'</td>\n",
       "      <td>Kampala, Uganda'</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-10-17 21:32:07 UTC</td>\n",
       "      <td>2022-10-05 17:43:39.452314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>FXWinnerEA</td>\n",
       "      <td>37732283081273344</td>\n",
       "      <td>FOREX LORD\\\\U0001f525\\\\U0001f4b0'</td>\n",
       "      <td>@ashley_forex</td>\n",
       "      <td>3275</td>\n",
       "      <td>77</td>\n",
       "      <td>242</td>\n",
       "      <td>123</td>\n",
       "      <td>Forex trader/crypto// Risk taker\\\\u270a\\\\U0001...</td>\n",
       "      <td>\\\\U0001f4b5\\\\U0001f4b4\\\\U0001f4b8'</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-03-11 13:29:25 UTC</td>\n",
       "      <td>2022-10-05 17:43:39.452314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>FXWinnerEA</td>\n",
       "      <td>36331479190044680</td>\n",
       "      <td>ZMB_NVT'</td>\n",
       "      <td>@230807Recycle</td>\n",
       "      <td>102</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>'</td>\n",
       "      <td>Ulju-gun, Republic of Korea'</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-09-10 14:11:42 UTC</td>\n",
       "      <td>2022-10-05 17:43:39.452314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2049 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Follower of            User ID                                 Name  \\\n",
       "0     FXWinnerEA             781065                          syafrizan'    \n",
       "1     FXWinnerEA   4532559400689667                  oluaye federation'    \n",
       "2     FXWinnerEA           16249377                            feraazz'    \n",
       "3     FXWinnerEA             458493                          Tokumendo'    \n",
       "4     FXWinnerEA  47273373018157060                       ashkan koala'    \n",
       "...          ...                ...                                  ...   \n",
       "2044  FXWinnerEA  32278163385987072                          EasyForex'    \n",
       "2045  FXWinnerEA  99271220345688064                           Bigbucks'    \n",
       "2046  FXWinnerEA  17579047984156672                        Merlin Emnx'    \n",
       "2047  FXWinnerEA  37732283081273344   FOREX LORD\\\\U0001f525\\\\U0001f4b0'    \n",
       "2048  FXWinnerEA  36331479190044680                            ZMB_NVT'    \n",
       "\n",
       "            Screen Name Following Followers  Likes  Tweets  \\\n",
       "0           @icaudumai       171        40     24     159    \n",
       "1     @Tijaniadewalew1        87        15     36      52    \n",
       "2          @feraazz001      2244       818     37      42    \n",
       "3           @tokumendo      2271       238   3676   23454    \n",
       "4         @AshkanKoala       211       116     23       4    \n",
       "...                 ...       ...       ...    ...     ...   \n",
       "2044       @EasyForex4      3995      5464    389     757    \n",
       "2045     @bigbucks2006      3211       963     81    3876    \n",
       "2046       @MerlinEmnx      1342       275    198      12    \n",
       "2047     @ashley_forex      3275        77    242     123    \n",
       "2048    @230807Recycle       102        11     34       3    \n",
       "\n",
       "                                                    Bio  \\\n",
       "0                Negara yang sarat dengan berita hoax'    \n",
       "1                                                male'    \n",
       "2                                        Forex trader'    \n",
       "3                                                    '    \n",
       "4     \\\\U0001f4bbMQLprogrammer and forex strategy bu...   \n",
       "...                                                 ...   \n",
       "2044  #forex #forextrader #bitcoin #trading #forextr...   \n",
       "2045                                Stocks and shares'    \n",
       "2046               Am slow walker but never well back'    \n",
       "2047  Forex trader/crypto// Risk taker\\\\u270a\\\\U0001...   \n",
       "2048                                                 '    \n",
       "\n",
       "                                 Location                       URL Verified  \\\n",
       "0                             indonesia'                              False    \n",
       "1                               Nigeria'                              False    \n",
       "2            Vereinigtes K\\\\xf6nigreich'                              False    \n",
       "3                 S\\\\xe3o Paulo, Brasil'                              False    \n",
       "4                                      '   https://t.co/qmIZ6jpYHp    False    \n",
       "...                                   ...                       ...      ...   \n",
       "2044                             Sweden'   https://t.co/nCqaaJY48i    False    \n",
       "2045                                   '                              False    \n",
       "2046                    Kampala, Uganda'                              False    \n",
       "2047  \\\\U0001f4b5\\\\U0001f4b4\\\\U0001f4b8'                              False    \n",
       "2048        Ulju-gun, Republic of Korea'                              False    \n",
       "\n",
       "     Private                    Joined                         UTC  \n",
       "0     False   2009-09-09 06:11:08 UTC   2022-10-05 17:43:39.452314  \n",
       "1     False   2022-03-17 18:58:21 UTC   2022-10-05 17:43:39.452314  \n",
       "2     False   2014-12-11 21:10:55 UTC   2022-10-05 17:43:39.452314  \n",
       "3     False   2009-06-30 17:30:54 UTC   2022-10-05 17:43:39.452314  \n",
       "4     False   2021-01-07 20:07:07 UTC   2022-10-05 17:43:39.452314  \n",
       "...      ...                       ...                         ...  \n",
       "2044  False   2020-02-25 12:16:35 UTC   2022-10-05 17:43:39.452314  \n",
       "2045  False   2020-08-28 09:03:00 UTC   2022-10-05 17:43:39.452314  \n",
       "2046  False   2020-10-17 21:32:07 UTC   2022-10-05 17:43:39.452314  \n",
       "2047  False   2020-03-11 13:29:25 UTC   2022-10-05 17:43:39.452314  \n",
       "2048   True   2021-09-10 14:11:42 UTC   2022-10-05 17:43:39.452314  \n",
       "\n",
       "[2049 rows x 15 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54737312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Follower of',\n",
      " 'User ID',\n",
      " 'Name',\n",
      " 'Screen Name',\n",
      " 'Following',\n",
      " 'Followers',\n",
      " 'Likes',\n",
      " 'Tweets',\n",
      " 'Bio',\n",
      " 'Location',\n",
      " 'URL',\n",
      " 'Verified',\n",
      " 'Private',\n",
      " 'Joined',\n",
      " 'UTC']\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "column_headers = list(excel_data_df.columns.values)\n",
    "pprint(column_headers)\n",
    "print(len(column_headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16316942",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = cx_Oracle.connect(user='edge', password='edge', dsn='orclpdb')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba38d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "send_error_oracle = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb744420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for i,row in excel_data_df.iterrows():\n",
    "    try:\n",
    "        c.callproc('edge_load_tusers',list(row))\n",
    "    except:\n",
    "        send_error_oracle.append(list(row))\n",
    "        pass\n",
    "error_df = pd.DataFrame(send_error_oracle,\n",
    "                  columns = ['Follower of', 'User ID', 'Name', 'Screen Name', 'Following', 'Followers', 'Likes', 'Tweets', 'Bio', 'Location', 'URL', 'Verified', 'Private', 'Joined', 'UTC'])\n",
    "error_df.to_excel(\"records_not_sent_to_oracleDB.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
